{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "JwCW14oFIlny",
        "outputId": "8bbde4e3-4481-4be1-9529-0c9c6dd8e1cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1/10, Loss: 0.2650423752261139\n",
            "Epoch 2/10, Loss: 0.06968034990032566\n",
            "Epoch 3/10, Loss: 0.04919354182899868\n",
            "Epoch 4/10, Loss: 0.040808340697493437\n",
            "Epoch 5/10, Loss: 0.03349337851528008\n",
            "Epoch 6/10, Loss: 0.02698583355757593\n",
            "Epoch 7/10, Loss: 0.025715534738022964\n",
            "Epoch 8/10, Loss: 0.021337849199402032\n",
            "Epoch 9/10, Loss: 0.018410215855380687\n",
            "Epoch 10/10, Loss: 0.016442271527574426\n",
            "Training complete. Weights saved as 'lenet_mnist_weights.pth'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_eb142214-9212-47b1-b624-c5f7a9d92468\", \"lenet_mnist_weights.pth\", 181792)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from PIL import Image, ImageFont, ImageDraw\n",
        "import numpy as np\n",
        "import imgaug.augmenters as iaa\n",
        "import os\n",
        "import cv2\n",
        "import string\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Define the LeNet model\n",
        "# Define the LeNet model with features and classifier split\n",
        "class LeNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        # Feature extractor\n",
        "        self.features = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 6, kernel_size=5),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2),\n",
        "            torch.nn.Conv2d(6, 16, kernel_size=5),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        # Classifier\n",
        "        self.classifier = torch.nn.Sequential(\n",
        "            torch.nn.Linear(16 * 4 * 4, 120),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(120, 84),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(84, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def train_lenet_on_mnist():\n",
        "    \"\"\"Train LeNet on the MNIST dataset and save the trained weights.\"\"\"\n",
        "    # Define transformations\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    # Load MNIST dataset\n",
        "    trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "    # Initialize the model, loss function, and optimizer\n",
        "    model = LeNet().to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Training loop\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f\"Using device: {device}\")\n",
        "    epochs = 10\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in trainloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {running_loss / len(trainloader)}\")\n",
        "\n",
        "    # Save the trained weights\n",
        "    torch.save(model.state_dict(), 'lenet_mnist_weights.pth')\n",
        "    print(\"Training complete. Weights saved as 'lenet_mnist_weights.pth'.\")\n",
        "\n",
        "\n",
        "# Execute the training process\n",
        "if __name__ == \"__main__\":\n",
        "    train_lenet_on_mnist()\n",
        "\n",
        "# Colab-specific code (if running on Colab)\n",
        "# Uncomment the following lines if running in Google Colab to download the weights\n",
        "from google.colab import files\n",
        "files.download('lenet_mnist_weights.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations (must match the ones used during training)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load MNIST test set\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Load trained model\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = LeNet().to(device)\n",
        "model.load_state_dict(torch.load('lenet_mnist_weights.pth', weights_only=True))\n",
        "model.eval()\n",
        "\n",
        "# Test set evaluation\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0SFqJ23uejL",
        "outputId": "f700d8fc-e7ce-4e13-c955-7c109d9b9e68"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 98.88%\n"
          ]
        }
      ]
    }
  ]
}